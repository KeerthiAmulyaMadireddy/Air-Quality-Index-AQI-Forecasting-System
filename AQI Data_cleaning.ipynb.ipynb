{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecb94773-0597-4a61-9c23-8105434d62ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83C\uDF0D Air Quality Index (AQI) Forecasting and Early Warning System for Indian Cities\n",
    "\n",
    "**Author:** Keerthi Amulya\n",
    "**Date:** January 31, 2026  \n",
    "**Challenge:** Databricks 14-Days AI Challenge - Capstone Project  \n",
    "**Sponsors:** Databricks | Codebasics | Indian Data Club\n",
    "\n",
    "---\n",
    "\n",
    "## \uD83D\uDCCB Table of Contents\n",
    "\n",
    "1. Executive Summary & Problem Statement\n",
    "2. Data Acquisition & Setup\n",
    "3. Data Cleaning (bronze to silver)\n",
    "4. Feature Engineering & Gold Layer\n",
    "6. Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1e439fa-3dc6-4216-82b7-e89926d42788",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "---\n",
    "# 1. Executive Summary & Problem Statement\n",
    "\n",
    "## 1.1 The Challenge: Air Pollution Crisis in India\n",
    "\n",
    "Air pollution has become one of India's most pressing public health emergencies. According to the World Health Organization, **13 of the world's 20 most polluted cities are in India**. Every year, air pollution contributes to over 1.67 million premature deaths in the country, making it a silent killer that affects millions of citizens daily.\n",
    "\n",
    "### Current Limitations:\n",
    "- **Reactive Monitoring:** Current AQI systems only report historical data, not predictions\n",
    "- **No Advance Warning:** Citizens cannot plan outdoor activities safely\n",
    "- **Healthcare Unpreparedness:** Hospitals face sudden surges in respiratory cases\n",
    "- **Policy Delays:** Government interventions happen after pollution events occur\n",
    "\n",
    "## 1.2 Our Solution: AI-Powered Predictive System\n",
    "\n",
    "We propose an **intelligent AQI forecasting and early warning system** that:\n",
    "\n",
    "1. **Predicts AQI values 3-7 days in advance** using historical patterns and machine learning\n",
    "2. **Identifies pollution trends** across different cities and seasons\n",
    "3. **Generates early warnings** when AQI is predicted to exceed safe thresholds\n",
    "4. **Provides actionable insights** for multiple stakeholders\n",
    "\n",
    "## 1.3 Target Stakeholders\n",
    "\n",
    "| Stakeholder | Use Case | Expected Benefit |\n",
    "|-------------|----------|------------------|\n",
    "| **Citizens** | Plan outdoor activities based on 7-day forecasts | Reduced health risks, better quality of life |\n",
    "| **Healthcare** | Prepare for respiratory case surges | Optimal resource allocation, lives saved |\n",
    "| **Policymakers** | Implement preventive traffic/industrial restrictions | Proactive pollution control, reduced severity |\n",
    "| **Researchers** | Analyze long-term pollution patterns | Better understanding of pollution drivers |\n",
    "\n",
    "## 1.4 Success Metrics\n",
    "\n",
    "- **Forecast Accuracy:** RMSE < 20 for 3-day predictions\n",
    "- **Classification Performance:** >85% accuracy for high pollution alerts\n",
    "- **Early Warning Precision:** Catch 90%+ of severe pollution events with <15% false alarms\n",
    "- **Business Impact:** Enable advance planning for 50+ million people across major cities\n",
    "\n",
    "## 1.5 Dataset Overview\n",
    "\n",
    "**Source:** Central Pollution Control Board (CPCB) Daily AQI Bulletins  \n",
    "**Repository:** https://github.com/urbanemissionsinfo/AQI_bulletins  \n",
    "**Time Period:** 2015-2023 (9 years of daily measurements)  \n",
    "**Coverage:** 278+ cities across India  \n",
    "**Records:** ~300,000 daily observations  \n",
    "\n",
    "**Features:**\n",
    "- `date`: Date of measurement (YYYY-MM-DD)\n",
    "- `city`: Name of city\n",
    "- `aqi`: Average Air Quality Index value\n",
    "- `aqi_category`: Government-defined category (Good/Satisfactory/Moderate/Poor/Very Poor/Severe)\n",
    "- `station_count`: Number of active monitoring stations\n",
    "- `prominent_pollutant`: Primary pollutant driving AQI (PM2.5, PM10, NO2, CO, SO2, O3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f848f58b-2710-49dd-983d-1931454e8625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57eb6aec-2d32-47a7-ae0e-1500868f3366",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\nPySpark version: 4.0.0\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PySpark version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6aaa2e2-2fc9-48d5-9884-e3201bf87288",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "## 1.1 Unity Catalog Architecture Setup\n",
    "\n",
    "I implement the **Medallion Architecture** (Bronze → Silver → Gold) using Unity Catalog for proper data governance and organization.\n",
    "\n",
    "### Architecture Overview:\n",
    "```\n",
    "aqi_india (Catalog)\n",
    "├── bronze (Raw Data Layer)\n",
    "│   └── aqi_bulletins (Raw ingestion)\n",
    "├── silver (Cleaned Data Layer)\n",
    "│   └── aqi_cleaned (Validated & transformed)\n",
    "└── gold (Analytics Layer)\n",
    "    ├── aqi_ml_features (ML-ready dataset)\n",
    "    ├── city_summary (Aggregated city stats)\n",
    "    └── monthly_trends (Time-based aggregates)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8306af94-ee5d-41ef-891d-eddc75345aa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using RAW_PATH: dbfs:/Volumes/aqi_india/bronze/raw_data/AllIndiaBulletins_Master.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import re\n",
    "\n",
    "# Widgets (optional)\n",
    "try:\n",
    "    dbutils.widgets.text(\"raw_dir\", \"/Volumes/aqi_india/bronze/raw_data/\")\n",
    "    dbutils.widgets.text(\"raw_file_hint\", \"AllIndiaBulletins\")\n",
    "except Exception as e:\n",
    "    print(\"Widgets not available:\", e)\n",
    "\n",
    "RAW_DIR = None\n",
    "HINT = None\n",
    "try:\n",
    "    RAW_DIR = dbutils.widgets.get(\"raw_dir\")\n",
    "    HINT = dbutils.widgets.get(\"raw_file_hint\")\n",
    "except Exception:\n",
    "    RAW_DIR = \"/Volumes/aqi_india/bronze/raw_data/\"\n",
    "    HINT = \"AllIndiaBulletins\"\n",
    "\n",
    "CATALOG = \"aqi_india\"\n",
    "\n",
    "# Create UC objects if supported (safe to re-run)\n",
    "try:\n",
    "    spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.bronze\")\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.silver\")\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.gold\")\n",
    "    spark.sql(f\"CREATE VOLUME IF NOT EXISTS {CATALOG}.bronze.raw_data\")\n",
    "except Exception as e:\n",
    "    print(\"Unity Catalog/Volume create skipped (not supported here):\", e)\n",
    "\n",
    "T_BRONZE = f\"{CATALOG}.bronze.aqi_bulletins\"\n",
    "T_SILVER = f\"{CATALOG}.silver.aqi_cleaned\"\n",
    "T_GOLD   = f\"{CATALOG}.gold.aqi_ml_features\"\n",
    "\n",
    "# Auto-pick a CSV from RAW_DIR\n",
    "raw_files = []\n",
    "try:\n",
    "    raw_files = [f.path for f in dbutils.fs.ls(RAW_DIR) if f.path.lower().endswith(\".csv\")]\n",
    "except Exception as e:\n",
    "    print(\"Could not list RAW_DIR:\", RAW_DIR, e)\n",
    "\n",
    "if not raw_files:\n",
    "    raise Exception(f\"No CSV found in {RAW_DIR}. Upload AllIndiaBulletins CSV to this folder first.\")\n",
    "\n",
    "candidates = [p for p in raw_files if re.search(HINT, p, re.I)]\n",
    "RAW_PATH = candidates[0] if candidates else raw_files[0]\n",
    "print(\"✅ Using RAW_PATH:\", RAW_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e533ed71-0ef0-4269-a66e-a174f61a0855",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# 2. Data Cleaning - Bronze to Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ee606f6-c7e0-42be-8b22-a8b19f4b4522",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\nDATA CLEANING PROCESS\n================================================================================\nRaw records loaded: 299,976\n\nSchema (note: city is STRING, not double):\nroot\n |-- date: string (nullable = true)\n |-- city: string (nullable = true)\n |-- station_count: integer (nullable = true)\n |-- air_quality: string (nullable = true)\n |-- aqi: double (nullable = true)\n |-- prominent_pollutant: string (nullable = true)\n\nBronze table created: aqi_india.bronze.aqi_bulletins (rows=299,976)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATA CLEANING PROCESS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "correct_schema = StructType([\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"station_count\", IntegerType(), True),\n",
    "    StructField(\"air_quality\", StringType(), True),\n",
    "    StructField(\"aqi\", DoubleType(), True),\n",
    "    StructField(\"prominent_pollutant\", StringType(), True)\n",
    "])\n",
    "\n",
    "raw_df = spark.read.csv(\n",
    "    RAW_PATH,\n",
    "    header=True,\n",
    "    schema=correct_schema\n",
    ")\n",
    "\n",
    "print(f\"Raw records loaded: {raw_df.count():,}\")\n",
    "print(\"\\nSchema (note: city is STRING, not double):\")\n",
    "raw_df.printSchema()\n",
    "\n",
    "bronze_df = raw_df.withColumn(\"ingested_at\", current_timestamp()).withColumn(\"raw_file\", lit(RAW_PATH))\n",
    "(bronze_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\",\"true\")\n",
    "    .saveAsTable(T_BRONZE)\n",
    ")\n",
    "print(f\"Bronze table created: {T_BRONZE} (rows={bronze_df.count():,})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4ff275f-6548-4e9e-b8c4-5b714cdd6293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample cities from raw data:\n+---------+\n|city     |\n+---------+\n|Lucknow  |\n|NULL     |\n|Agra     |\n|Chennai  |\n|Haldia   |\n|Panchkula|\n|Rohtak   |\n|Jaipur   |\n|Gaya     |\n|Faridabad|\n+---------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample cities from raw data:\")\n",
    "raw_df.select(\"city\").distinct().show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "723392ca-ae43-404e-aa34-260e2fed6021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Remove Corrupted Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "642c322b-db46-4695-85c4-b2efc105651b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Removing corrupted rows\n------------------------------------------------------------\nClean records: 299,972\nRemoved: 4 corrupted rows (0.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 1: Removing corrupted rows\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "starting_count = raw_df.count()\n",
    "\n",
    "# Remove rows where critical fields are NULL or date is malformed\n",
    "silver_df = raw_df.filter(\n",
    "    col(\"city\").isNotNull() & \n",
    "    col(\"aqi\").isNotNull() & \n",
    "    col(\"date\").rlike(\"^\\\\d{4}-\\\\d{2}-\\\\d{2}$\")\n",
    ")\n",
    "\n",
    "removed = starting_count - silver_df.count()\n",
    "print(f\"Clean records: {silver_df.count():,}\")\n",
    "print(f\"Removed: {removed:,} corrupted rows ({removed/starting_count*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42f12ba9-305c-48a6-8f16-5f108bce46a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Parse and Validate Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44474087-f893-495b-b866-9ceb1d1d8e9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Converting and validating dates\n------------------------------------------------------------\nValid dates: 299,972\nDate range: 2015-05-01 to 2023-12-31\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 2: Converting and validating dates\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Convert string date to proper date type\n",
    "silver_df = silver_df.withColumn(\"date_parsed\", to_date(col(\"date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Filter only valid dates (2015-2023)\n",
    "silver_df = silver_df.filter(\n",
    "    (year(col(\"date_parsed\")) >= 2015) & \n",
    "    (year(col(\"date_parsed\")) <= 2023)\n",
    ")\n",
    "\n",
    "date_range = silver_df.agg(\n",
    "    min(\"date_parsed\").alias(\"min_date\"),\n",
    "    max(\"date_parsed\").alias(\"max_date\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Valid dates: {silver_df.count():,}\")\n",
    "print(f\"Date range: {date_range['min_date']} to {date_range['max_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec722d2f-c6b3-44e6-bc87-5f2a2ad3cf18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3: Filter Invalid AQI Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02e61b80-ce29-4bbb-86de-16e22332fe0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: Filtering invalid AQI values\n------------------------------------------------------------\nValid AQI records: 299,972\nRemoved: 0 invalid AQI values\nAQI range: 3.0 to 500.0\nAverage AQI: 124.69\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 3: Filtering invalid AQI values\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "before_count = silver_df.count()\n",
    "\n",
    "# Valid AQI range: 0-999\n",
    "silver_df = silver_df.filter(\n",
    "    (col(\"aqi\") >= 0) & \n",
    "    (col(\"aqi\") <= 999)\n",
    ")\n",
    "\n",
    "removed = before_count - silver_df.count()\n",
    "\n",
    "aqi_stats = silver_df.agg(\n",
    "    min(\"aqi\").alias(\"min_aqi\"),\n",
    "    max(\"aqi\").alias(\"max_aqi\"),\n",
    "    avg(\"aqi\").alias(\"avg_aqi\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Valid AQI records: {silver_df.count():,}\")\n",
    "print(f\"Removed: {removed:,} invalid AQI values\")\n",
    "print(f\"AQI range: {aqi_stats['min_aqi']:.1f} to {aqi_stats['max_aqi']:.1f}\")\n",
    "print(f\"Average AQI: {aqi_stats['avg_aqi']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd906135-0e6e-4bff-be32-8ec475d7da41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4: Validate Station Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "778920e1-0c19-4f2f-a956-5cd9e988c01d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: Handling station counts\n------------------------------------------------------------\nStation range: 1 to 39\nAverage stations: 1.80\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 4: Handling station counts\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Fill NULL station counts with 1 (minimum reasonable value)\n",
    "silver_df = silver_df.withColumn(\n",
    "    \"station_count\",\n",
    "    when(col(\"station_count\").isNull(), 1)\n",
    "    .when(col(\"station_count\") <= 0, 1)\n",
    "    .otherwise(col(\"station_count\"))\n",
    ")\n",
    "\n",
    "station_stats = silver_df.agg(\n",
    "    min(\"station_count\").alias(\"min_stations\"),\n",
    "    max(\"station_count\").alias(\"max_stations\"),\n",
    "    avg(\"station_count\").alias(\"avg_stations\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Station range: {station_stats['min_stations']} to {station_stats['max_stations']}\")\n",
    "print(f\"Average stations: {station_stats['avg_stations']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53f7aa81-9255-4172-adba-02b557a1d098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 5: Standardize City Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5049aa5b-ae4a-44e8-aecb-2b3bca6b1f1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: Standardizing city names\n------------------------------------------------------------\nCities before: 277\nCities after: 275\nMerged 2 duplicate city name variations\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 5: Standardizing city names\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "before_cities = silver_df.select(\"city\").distinct().count()\n",
    "\n",
    "# Standardize major city name variations\n",
    "silver_df = silver_df.withColumn(\"city_clean\",\n",
    "    when(col(\"city\").like(\"%Delhi%\"), \"Delhi\")\n",
    "    .when(col(\"city\").like(\"%Mumbai%\"), \"Mumbai\")\n",
    "    .when(col(\"city\").like(\"%Bengaluru%\"), \"Bengaluru\")\n",
    "    .when(col(\"city\").like(\"%Bangalore%\"), \"Bengaluru\")\n",
    "    .when(col(\"city\").like(\"%Hyderabad%\"), \"Hyderabad\")\n",
    "    .when(col(\"city\").like(\"%Chennai%\"), \"Chennai\")\n",
    "    .when(col(\"city\").like(\"%Kolkata%\"), \"Kolkata\")\n",
    "    .when(col(\"city\").like(\"%Pune%\"), \"Pune\")\n",
    "    .when(col(\"city\").like(\"%Ahmedabad%\"), \"Ahmedabad\")\n",
    "    .when(col(\"city\").like(\"%Jaipur%\"), \"Jaipur\")\n",
    "    .when(col(\"city\").like(\"%Lucknow%\"), \"Lucknow\")\n",
    "    .when(col(\"city\").like(\"%Kanpur%\"), \"Kanpur\")\n",
    "    .when(col(\"city\").like(\"%Nagpur%\"), \"Nagpur\")\n",
    "    .when(col(\"city\").like(\"%Indore%\"), \"Indore\")\n",
    "    .when(col(\"city\").like(\"%Thane%\"), \"Thane\")\n",
    "    .when(col(\"city\").like(\"%Bhopal%\"), \"Bhopal\")\n",
    "    .when(col(\"city\").like(\"%Pimpri%\"), \"Pimpri-Chinchwad\")\n",
    "    .when(col(\"city\").like(\"%Patna%\"), \"Patna\")\n",
    "    .when(col(\"city\").like(\"%Vadodara%\"), \"Vadodara\")\n",
    "    .when(col(\"city\").like(\"%Ghaziabad%\"), \"Ghaziabad\")\n",
    "    .when(col(\"city\").like(\"%Agra%\"), \"Agra\")\n",
    "    .when(col(\"city\").like(\"%Nashik%\"), \"Nashik\")\n",
    "    .when(col(\"city\").like(\"%Faridabad%\"), \"Faridabad\")\n",
    "    .otherwise(trim(col(\"city\")))\n",
    ")\n",
    "\n",
    "after_cities = silver_df.select(\"city_clean\").distinct().count()\n",
    "\n",
    "print(f\"Cities before: {before_cities}\")\n",
    "print(f\"Cities after: {after_cities}\")\n",
    "print(f\"Merged {before_cities - after_cities} duplicate city name variations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd7fe51d-fad0-4f65-bb49-31bcae5efa9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 6: Remove Duplicate Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47c339f2-6238-44db-9418-ae7a1ddb2ce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 6: Removing duplicate date-city combinations\n------------------------------------------------------------\nUnique records: 297,209\nRemoved: 2,763 duplicate records (0.92%)\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 6: Removing duplicate date-city combinations\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "before_count = silver_df.count()\n",
    "\n",
    "# Keep only unique date-city combinations (keep first occurrence)\n",
    "silver_df = silver_df.dropDuplicates([\"date_parsed\", \"city_clean\"])\n",
    "\n",
    "removed = before_count - silver_df.count()\n",
    "\n",
    "print(f\"Unique records: {silver_df.count():,}\")\n",
    "print(f\"Removed: {removed:,} duplicate records ({removed/before_count*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa0f282c-f364-4d44-b26a-aab5f2f741c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 7: Add Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1cc1b4d-e8af-4f9b-b406-72ef7debf8b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 7: Adding temporal features\n------------------------------------------------------------\nAdded temporal features: year, month, day_of_week, day_of_month\nAdded: quarter, week_of_year, is_weekend, season\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 7: Adding temporal features\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Extract temporal components\n",
    "silver_df = silver_df \\\n",
    "    .withColumn(\"year\", year(\"date_parsed\")) \\\n",
    "    .withColumn(\"month\", month(\"date_parsed\")) \\\n",
    "    .withColumn(\"day_of_week\", dayofweek(\"date_parsed\")) \\\n",
    "    .withColumn(\"day_of_month\", dayofmonth(\"date_parsed\")) \\\n",
    "    .withColumn(\"quarter\", quarter(\"date_parsed\")) \\\n",
    "    .withColumn(\"week_of_year\", weekofyear(\"date_parsed\")) \\\n",
    "    .withColumn(\"is_weekend\", \n",
    "        when(col(\"day_of_week\").isin([1, 7]), True).otherwise(False)\n",
    "    ) \\\n",
    "    .withColumn(\"season\",\n",
    "        when(col(\"month\").isin([12, 1, 2]), \"Winter\")\n",
    "        .when(col(\"month\").isin([3, 4, 5]), \"Spring\")\n",
    "        .when(col(\"month\").isin([6, 7, 8, 9]), \"Monsoon\")\n",
    "        .otherwise(\"Autumn\")\n",
    "    )\n",
    "\n",
    "print(\"Added temporal features: year, month, day_of_week, day_of_month\")\n",
    "print(\"Added: quarter, week_of_year, is_weekend, season\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcfa8119-424d-4c62-81cf-9193a8fce7e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 8: Create AQI Risk Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b351cf1f-c5ae-4bcb-ae26-ab6b16142c8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 8: Creating AQI risk categorization\n------------------------------------------------------------\nCreated risk levels: Good, Satisfactory, Moderate, Poor, Very Poor, Severe\nCreated numeric categories 1-6\nCreated binary flags: is_high_pollution, is_severe_pollution\n+--------------+------+\n|aqi_risk_level| count|\n+--------------+------+\n|  Satisfactory|104064|\n|      Moderate| 95004|\n|          Good| 47287|\n|          Poor| 34378|\n|     Very Poor| 13962|\n|        Severe|  2514|\n+--------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 8: Creating AQI risk categorization\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Standard AQI risk levels per CPCB guidelines\n",
    "silver_df = silver_df.withColumn(\"aqi_risk_level\",\n",
    "    when(col(\"aqi\") <= 50, \"Good\")\n",
    "    .when(col(\"aqi\") <= 100, \"Satisfactory\")\n",
    "    .when(col(\"aqi\") <= 200, \"Moderate\")\n",
    "    .when(col(\"aqi\") <= 300, \"Poor\")\n",
    "    .when(col(\"aqi\") <= 400, \"Very Poor\")\n",
    "    .otherwise(\"Severe\")\n",
    ")\n",
    "\n",
    "# Numeric category for ML\n",
    "silver_df = silver_df.withColumn(\"aqi_numeric_category\",\n",
    "    when(col(\"aqi\") <= 50, 1)\n",
    "    .when(col(\"aqi\") <= 100, 2)\n",
    "    .when(col(\"aqi\") <= 200, 3)\n",
    "    .when(col(\"aqi\") <= 300, 4)\n",
    "    .when(col(\"aqi\") <= 400, 5)\n",
    "    .otherwise(6)\n",
    ")\n",
    "\n",
    "# Binary risk flags\n",
    "silver_df = silver_df.withColumn(\"is_high_pollution\", col(\"aqi\") > 200)\n",
    "silver_df = silver_df.withColumn(\"is_severe_pollution\", col(\"aqi\") > 400)\n",
    "\n",
    "print(\"Created risk levels: Good, Satisfactory, Moderate, Poor, Very Poor, Severe\")\n",
    "print(\"Created numeric categories 1-6\")\n",
    "print(\"Created binary flags: is_high_pollution, is_severe_pollution\")\n",
    "\n",
    "# Show distribution\n",
    "silver_df.groupBy(\"aqi_risk_level\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d97e74f-4687-4c55-85be-37c3cbf1a5b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 9: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8aa32235-dd34-4c1d-9c7c-20aeccab619a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 9: Handling missing values\n------------------------------------------------------------\nNULL counts in critical columns:\n+----------+----------+---------+---------------+\n|date_nulls|city_nulls|aqi_nulls|pollutant_nulls|\n+----------+----------+---------+---------------+\n|         0|         0|        0|              0|\n+----------+----------+---------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 9: Handling missing values\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Fill missing pollutant with 'Unknown'\n",
    "silver_df = silver_df.withColumn(\"prominent_pollutant\",\n",
    "    when(col(\"prominent_pollutant\").isNull(), \"Unknown\")\n",
    "    .otherwise(trim(col(\"prominent_pollutant\")))\n",
    ")\n",
    "\n",
    "# Fill missing air_quality with derived risk level\n",
    "silver_df = silver_df.withColumn(\"air_quality\",\n",
    "    when(col(\"air_quality\").isNull(), col(\"aqi_risk_level\"))\n",
    "    .otherwise(trim(col(\"air_quality\")))\n",
    ")\n",
    "\n",
    "# Verify no NULLs in critical columns\n",
    "print(\"NULL counts in critical columns:\")\n",
    "silver_df.select(\n",
    "    count(when(col(\"date_parsed\").isNull(), 1)).alias(\"date_nulls\"),\n",
    "    count(when(col(\"city_clean\").isNull(), 1)).alias(\"city_nulls\"),\n",
    "    count(when(col(\"aqi\").isNull(), 1)).alias(\"aqi_nulls\"),\n",
    "    count(when(col(\"prominent_pollutant\").isNull(), 1)).alias(\"pollutant_nulls\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d9b1369-977a-4eca-8c9a-6d21cc09d210",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 10: Create Final Silver Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c95b7de5-e649-4b7c-b3bc-5a71ee203d70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 10: Creating final Silver layer schema\n------------------------------------------------------------\nFinal Silver records: 297,209\nFinal Silver columns: 20\n\nSchema:\nroot\n |-- date: date (nullable = true)\n |-- city: string (nullable = true)\n |-- aqi: double (nullable = true)\n |-- station_count: integer (nullable = true)\n |-- air_quality: string (nullable = true)\n |-- aqi_risk_level: string (nullable = false)\n |-- aqi_category: integer (nullable = false)\n |-- prominent_pollutant: string (nullable = true)\n |-- year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day_of_week: integer (nullable = true)\n |-- day_of_month: integer (nullable = true)\n |-- quarter: integer (nullable = true)\n |-- week_of_year: integer (nullable = true)\n |-- season: string (nullable = false)\n |-- is_weekend: boolean (nullable = false)\n |-- is_high_pollution: boolean (nullable = true)\n |-- is_severe_pollution: boolean (nullable = true)\n |-- processed_timestamp: timestamp (nullable = false)\n |-- data_quality_flag: string (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 10: Creating final Silver layer schema\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "silver_final = silver_df.select(\n",
    "    # Core fields\n",
    "    col(\"date_parsed\").alias(\"date\"),\n",
    "    col(\"city_clean\").alias(\"city\"),\n",
    "    col(\"aqi\"),\n",
    "    col(\"station_count\"),\n",
    "    \n",
    "    # Categories\n",
    "    col(\"air_quality\"),\n",
    "    col(\"aqi_risk_level\"),\n",
    "    col(\"aqi_numeric_category\").alias(\"aqi_category\"),\n",
    "    col(\"prominent_pollutant\"),\n",
    "    \n",
    "    # Temporal features\n",
    "    col(\"year\"),\n",
    "    col(\"month\"),\n",
    "    col(\"day_of_week\"),\n",
    "    col(\"day_of_month\"),\n",
    "    col(\"quarter\"),\n",
    "    col(\"week_of_year\"),\n",
    "    col(\"season\"),\n",
    "    col(\"is_weekend\"),\n",
    "    \n",
    "    # Risk flags\n",
    "    col(\"is_high_pollution\"),\n",
    "    col(\"is_severe_pollution\"),\n",
    "    \n",
    "    # Metadata\n",
    "    current_timestamp().alias(\"processed_timestamp\"),\n",
    "    lit(\"silver_v1\").alias(\"data_quality_flag\")\n",
    ")\n",
    "\n",
    "print(f\"Final Silver records: {silver_final.count():,}\")\n",
    "print(f\"Final Silver columns: {len(silver_final.columns)}\")\n",
    "print(\"\\nSchema:\")\n",
    "silver_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6969b767-f853-4bac-b068-c13fcad4f2db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data from Silver layer:\n+----------+---------+-----+--------------+-------+\n|      date|     city|  aqi|aqi_risk_level| season|\n+----------+---------+-----+--------------+-------+\n|2015-05-07|    Delhi|254.0|          Poor| Spring|\n|2015-07-06|Ahmedabad| 89.0|  Satisfactory|Monsoon|\n|2015-10-01| Varanasi|164.0|      Moderate| Autumn|\n|2015-11-13|   Mumbai|113.0|      Moderate| Autumn|\n|2016-01-27|    Delhi|379.0|     Very Poor| Winter|\n|2016-01-28|  Lucknow|374.0|     Very Poor| Winter|\n|2016-03-16|     Gaya| 52.0|  Satisfactory| Spring|\n|2016-07-05|  Lucknow| 89.0|  Satisfactory|Monsoon|\n|2016-07-17|Panchkula| 39.0|          Good|Monsoon|\n|2016-08-17|   Mumbai| 55.0|  Satisfactory|Monsoon|\n+----------+---------+-----+--------------+-------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Verify city column has values\n",
    "print(\"Sample data from Silver layer:\")\n",
    "silver_final.select(\"date\", \"city\", \"aqi\", \"aqi_risk_level\", \"season\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "856bc7cc-ce0b-4f31-97df-09f7c4e17acf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Save Silver Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eecee15-41d0-4ade-8eea-d2d547033165",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Silver layer to Delta Lake...\n------------------------------------------------------------\nSilver table created: aqi_india.silver.aqi_cleaned\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving Silver layer to Delta Lake...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Write to Silver table with partitioning\n",
    "silver_final.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .saveAsTable(T_SILVER)\n",
    "\n",
    "print(\"Silver table created: aqi_india.silver.aqi_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49cbea14-8fd2-45d0-9eee-e0b36d199d6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Silver table...\nTable optimized with ZORDER (city, date)\n"
     ]
    }
   ],
   "source": [
    "# Optimize Silver table\n",
    "print(\"Optimizing Silver table...\")\n",
    "try:\n",
    "    spark.sql(f\"OPTIMIZE {T_SILVER} ZORDER BY (city, date)\")\n",
    "except Exception as e:\n",
    "    print(\"OPTIMIZE skipped:\", e)\n",
    "print(\"Table optimized with ZORDER (city, date)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5614a34f-ed0b-4fa9-9180-676041010403",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# 3. Feature Engineering - Gold Layer Creation\n",
    "\n",
    "Creating ML-ready features:\n",
    "1. Lag features (historical AQI)\n",
    "2. Rolling statistics\n",
    "3. Rate of change\n",
    "4. City baselines\n",
    "5. Cyclical encoding\n",
    "6. Target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7a651b5-3fb0-4fbe-ad0f-04d2c22b6bcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\nFEATURE ENGINEERING - GOLD LAYER CREATION\n================================================================================\n\nStarting with: 297,209 records from Silver layer\nCreating ML features...\n\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FEATURE ENGINEERING - GOLD LAYER CREATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load Silver data\n",
    "df_silver = spark.table(T_SILVER)\n",
    "\n",
    "print(f\"\\nStarting with: {df_silver.count():,} records from Silver layer\")\n",
    "print(\"Creating ML features...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "737304e0-26b3-492e-ac7a-81c4dcdc6d0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.1 Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f2ac9de-d2cd-4107-a145-19ac5fda86ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET 1: Lag features (historical AQI)\n------------------------------------------------------------\nCreated: aqi_lag_1, aqi_lag_3, aqi_lag_7, aqi_lag_14, aqi_lag_30\n"
     ]
    }
   ],
   "source": [
    "print(\"FEATURE SET 1: Lag features (historical AQI)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Window partitioned by city, ordered by date\n",
    "window_spec = Window.partitionBy(\"city\").orderBy(\"date\")\n",
    "\n",
    "# Create lag features\n",
    "gold_df = df_silver \\\n",
    "    .withColumn(\"aqi_lag_1\", lag(\"aqi\", 1).over(window_spec)) \\\n",
    "    .withColumn(\"aqi_lag_3\", lag(\"aqi\", 3).over(window_spec)) \\\n",
    "    .withColumn(\"aqi_lag_7\", lag(\"aqi\", 7).over(window_spec)) \\\n",
    "    .withColumn(\"aqi_lag_14\", lag(\"aqi\", 14).over(window_spec)) \\\n",
    "    .withColumn(\"aqi_lag_30\", lag(\"aqi\", 30).over(window_spec))\n",
    "\n",
    "print(\"Created: aqi_lag_1, aqi_lag_3, aqi_lag_7, aqi_lag_14, aqi_lag_30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17bb3e3f-b8be-4ccb-91b3-4ad6b48bc8a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.2 Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80c0a4f0-0437-477b-9436-fa199ccb7cee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET 2: Rolling window statistics\n------------------------------------------------------------\nCreated rolling averages: 7, 14, 30 days\nCreated rolling std dev: 7, 14 days\nCreated rolling min/max: 7 days\n"
     ]
    }
   ],
   "source": [
    "print(\"FEATURE SET 2: Rolling window statistics\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Rolling windows\n",
    "rolling_7 = Window.partitionBy(\"city\").orderBy(\"date\").rowsBetween(-6, 0)\n",
    "rolling_14 = Window.partitionBy(\"city\").orderBy(\"date\").rowsBetween(-13, 0)\n",
    "rolling_30 = Window.partitionBy(\"city\").orderBy(\"date\").rowsBetween(-29, 0)\n",
    "\n",
    "# Rolling averages\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"aqi_rolling_avg_7\", avg(\"aqi\").over(rolling_7)) \\\n",
    "    .withColumn(\"aqi_rolling_avg_14\", avg(\"aqi\").over(rolling_14)) \\\n",
    "    .withColumn(\"aqi_rolling_avg_30\", avg(\"aqi\").over(rolling_30))\n",
    "\n",
    "# Rolling std dev (volatility)\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"aqi_rolling_std_7\", stddev(\"aqi\").over(rolling_7)) \\\n",
    "    .withColumn(\"aqi_rolling_std_14\", stddev(\"aqi\").over(rolling_14))\n",
    "\n",
    "# Rolling min/max\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"aqi_rolling_max_7\", max(\"aqi\").over(rolling_7)) \\\n",
    "    .withColumn(\"aqi_rolling_min_7\", min(\"aqi\").over(rolling_7))\n",
    "\n",
    "print(\"Created rolling averages: 7, 14, 30 days\")\n",
    "print(\"Created rolling std dev: 7, 14 days\")\n",
    "print(\"Created rolling min/max: 7 days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58407d5c-a663-47e7-9766-046e8c2ea26e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.3 Rate of Change Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ed06043-81e9-486f-b1c2-2e1008ac1659",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET 3: Rate of change features\n------------------------------------------------------------\nCreated: aqi_change_1d, aqi_change_7d\nCreated: aqi_pct_change_1d, aqi_pct_change_7d\n"
     ]
    }
   ],
   "source": [
    "print(\"FEATURE SET 3: Rate of change features\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Absolute changes\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"aqi_change_1d\",\n",
    "        when(col(\"aqi_lag_1\").isNotNull(),\n",
    "             col(\"aqi\") - col(\"aqi_lag_1\")).otherwise(None)\n",
    "    ) \\\n",
    "    .withColumn(\"aqi_change_7d\",\n",
    "        when(col(\"aqi_lag_7\").isNotNull(),\n",
    "             col(\"aqi\") - col(\"aqi_lag_7\")).otherwise(None)\n",
    "    )\n",
    "\n",
    "# Percentage changes\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"aqi_pct_change_1d\",\n",
    "        when((col(\"aqi_lag_1\").isNotNull()) & (col(\"aqi_lag_1\") != 0),\n",
    "             ((col(\"aqi\") - col(\"aqi_lag_1\")) / col(\"aqi_lag_1\")) * 100).otherwise(None)\n",
    "    ) \\\n",
    "    .withColumn(\"aqi_pct_change_7d\",\n",
    "        when((col(\"aqi_lag_7\").isNotNull()) & (col(\"aqi_lag_7\") != 0),\n",
    "             ((col(\"aqi\") - col(\"aqi_lag_7\")) / col(\"aqi_lag_7\")) * 100).otherwise(None)\n",
    "    )\n",
    "\n",
    "print(\"Created: aqi_change_1d, aqi_change_7d\")\n",
    "print(\"Created: aqi_pct_change_1d, aqi_pct_change_7d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d8dd6de-b581-42ee-8117-e9d8c2fe5c7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.4 City-Level Baseline Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb6b8fff-ec8a-4695-b57d-d974a456ba07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET 4: City-level baseline statistics\n------------------------------------------------------------\nCreated: city_avg_aqi, city_std_aqi\nCreated: aqi_deviation_from_city_avg, aqi_z_score, aqi_percentile_in_city\n"
     ]
    }
   ],
   "source": [
    "print(\"FEATURE SET 4: City-level baseline statistics\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Calculate city-wide statistics\n",
    "city_stats = df_silver.groupBy(\"city\") \\\n",
    "    .agg(\n",
    "        avg(\"aqi\").alias(\"city_avg_aqi\"),\n",
    "        stddev(\"aqi\").alias(\"city_std_aqi\"),\n",
    "        min(\"aqi\").alias(\"city_min_aqi\"),\n",
    "        max(\"aqi\").alias(\"city_max_aqi\"),\n",
    "        count(\"*\").alias(\"city_record_count\")\n",
    "    )\n",
    "\n",
    "# Join back to main dataset\n",
    "gold_df = gold_df.join(city_stats, on=\"city\", how=\"left\")\n",
    "\n",
    "# Calculate deviation from baseline\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"aqi_deviation_from_city_avg\",\n",
    "        col(\"aqi\") - col(\"city_avg_aqi\")\n",
    "    ) \\\n",
    "    .withColumn(\"aqi_z_score\",\n",
    "        when(col(\"city_std_aqi\") != 0,\n",
    "             (col(\"aqi\") - col(\"city_avg_aqi\")) / col(\"city_std_aqi\")\n",
    "        ).otherwise(0)\n",
    "    ) \\\n",
    "    .withColumn(\"aqi_percentile_in_city\",\n",
    "        when(col(\"city_max_aqi\") != col(\"city_min_aqi\"),\n",
    "             (col(\"aqi\") - col(\"city_min_aqi\")) / (col(\"city_max_aqi\") - col(\"city_min_aqi\")) * 100\n",
    "        ).otherwise(50)\n",
    "    )\n",
    "\n",
    "print(\"Created: city_avg_aqi, city_std_aqi\")\n",
    "print(\"Created: aqi_deviation_from_city_avg, aqi_z_score, aqi_percentile_in_city\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11ef7996-0a97-48ef-9fc6-ecd6a6eeb65e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.5 Cyclical Temporal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cd07a77-085c-45f6-b434-3f7013c75f11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET 5: Cyclical temporal encodings\n------------------------------------------------------------\nCreated: month_sin, month_cos\nCreated: day_of_week_sin, day_of_week_cos\nCreated: day_of_month_sin, day_of_month_cos\n"
     ]
    }
   ],
   "source": [
    "print(\"FEATURE SET 5: Cyclical temporal encodings\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "import math\n",
    "PI = 3.14159265359\n",
    "\n",
    "# Month cyclical (handles Dec->Jan transition)\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"month_sin\", sin(col(\"month\") * 2 * PI / 12)) \\\n",
    "    .withColumn(\"month_cos\", cos(col(\"month\") * 2 * PI / 12))\n",
    "\n",
    "# Day of week cyclical\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"day_of_week_sin\", sin(col(\"day_of_week\") * 2 * PI / 7)) \\\n",
    "    .withColumn(\"day_of_week_cos\", cos(col(\"day_of_week\") * 2 * PI / 7))\n",
    "\n",
    "# Day of month cyclical\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"day_of_month_sin\", sin(col(\"day_of_month\") * 2 * PI / 31)) \\\n",
    "    .withColumn(\"day_of_month_cos\", cos(col(\"day_of_month\") * 2 * PI / 31))\n",
    "\n",
    "print(\"Created: month_sin, month_cos\")\n",
    "print(\"Created: day_of_week_sin, day_of_week_cos\")\n",
    "print(\"Created: day_of_month_sin, day_of_month_cos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fda3c8f3-8e8d-4db0-b9ed-6cff9bb90fc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.6 Target Variables for Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8f2834b-af3f-4298-b47c-e481b7a827df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET 6: Target variables for prediction\n------------------------------------------------------------\nCreated targets: aqi_next_1d, aqi_next_3d, aqi_next_7d\nCreated binary: target_high_aqi_tomorrow, target_severe_aqi_tomorrow\n"
     ]
    }
   ],
   "source": [
    "print(\"FEATURE SET 6: Target variables for prediction\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Future AQI values (prediction targets)\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"aqi_next_1d\", lead(\"aqi\", 1).over(window_spec)) \\\n",
    "    .withColumn(\"aqi_next_3d\", lead(\"aqi\", 3).over(window_spec)) \\\n",
    "    .withColumn(\"aqi_next_7d\", lead(\"aqi\", 7).over(window_spec))\n",
    "\n",
    "# Binary classification targets\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"target_high_aqi_tomorrow\",\n",
    "        when(col(\"aqi_next_1d\") > 200, 1).otherwise(0)\n",
    "    ) \\\n",
    "    .withColumn(\"target_severe_aqi_tomorrow\",\n",
    "        when(col(\"aqi_next_1d\") > 400, 1).otherwise(0)\n",
    "    )\n",
    "\n",
    "print(\"Created targets: aqi_next_1d, aqi_next_3d, aqi_next_7d\")\n",
    "print(\"Created binary: target_high_aqi_tomorrow, target_severe_aqi_tomorrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "760f5889-488a-40b6-aeb3-9e6792ffdcb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.7 Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc912613-2fbb-4cbf-b93d-dbfb569aba66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET 7: Interaction features\n------------------------------------------------------------\nCreated: is_winter_high_pollution_city\nCreated: weekend_pollution_delta\nCreated: is_reliable_measurement\n"
     ]
    }
   ],
   "source": [
    "print(\"FEATURE SET 7: Interaction features\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Winter high pollution cities flag\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"is_winter_high_pollution_city\",\n",
    "        when((col(\"season\") == \"Winter\") & \n",
    "             col(\"city\").isin([\"Delhi\", \"Ghaziabad\", \"Noida\", \"Gurugram\", \"Faridabad\"]), 1).otherwise(0)\n",
    "    )\n",
    "\n",
    "# Weekend effect\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"weekend_pollution_delta\",\n",
    "        when(col(\"is_weekend\") == True,\n",
    "             col(\"aqi\") - col(\"city_avg_aqi\")).otherwise(None)\n",
    "    )\n",
    "\n",
    "# Station reliability indicator\n",
    "gold_df = gold_df \\\n",
    "    .withColumn(\"is_reliable_measurement\",\n",
    "        when(col(\"station_count\") >= 3, True).otherwise(False)\n",
    "    )\n",
    "\n",
    "print(\"Created: is_winter_high_pollution_city\")\n",
    "print(\"Created: weekend_pollution_delta\")\n",
    "print(\"Created: is_reliable_measurement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6e9b7c8-153b-4501-823b-eb81bdb1149e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.8 Final Gold Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fc58fb9-0314-4cde-9afa-ffd603e89b76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL: Creating Gold layer schema\n------------------------------------------------------------\nGold layer records: 297,209\nGold layer features: 52\n\nSchema:\nroot\n |-- date: date (nullable = true)\n |-- city: string (nullable = true)\n |-- year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day_of_week: integer (nullable = true)\n |-- quarter: integer (nullable = true)\n |-- season: string (nullable = true)\n |-- aqi: double (nullable = true)\n |-- station_count: integer (nullable = true)\n |-- aqi_category: integer (nullable = true)\n |-- aqi_risk_level: string (nullable = true)\n |-- prominent_pollutant: string (nullable = true)\n |-- is_weekend: boolean (nullable = true)\n |-- is_high_pollution: boolean (nullable = true)\n |-- is_severe_pollution: boolean (nullable = true)\n |-- aqi_lag_1: double (nullable = true)\n |-- aqi_lag_3: double (nullable = true)\n |-- aqi_lag_7: double (nullable = true)\n |-- aqi_lag_14: double (nullable = true)\n |-- aqi_lag_30: double (nullable = true)\n |-- aqi_rolling_avg_7: double (nullable = true)\n |-- aqi_rolling_avg_14: double (nullable = true)\n |-- aqi_rolling_avg_30: double (nullable = true)\n |-- aqi_rolling_std_7: double (nullable = true)\n |-- aqi_rolling_std_14: double (nullable = true)\n |-- aqi_rolling_max_7: double (nullable = true)\n |-- aqi_rolling_min_7: double (nullable = true)\n |-- aqi_change_1d: double (nullable = true)\n |-- aqi_change_7d: double (nullable = true)\n |-- aqi_pct_change_1d: double (nullable = true)\n |-- aqi_pct_change_7d: double (nullable = true)\n |-- city_avg_aqi: double (nullable = true)\n |-- city_std_aqi: double (nullable = true)\n |-- aqi_deviation_from_city_avg: double (nullable = true)\n |-- aqi_z_score: double (nullable = true)\n |-- aqi_percentile_in_city: double (nullable = true)\n |-- month_sin: double (nullable = true)\n |-- month_cos: double (nullable = true)\n |-- day_of_week_sin: double (nullable = true)\n |-- day_of_week_cos: double (nullable = true)\n |-- day_of_month_sin: double (nullable = true)\n |-- day_of_month_cos: double (nullable = true)\n |-- is_winter_high_pollution_city: integer (nullable = false)\n |-- weekend_pollution_delta: double (nullable = true)\n |-- is_reliable_measurement: boolean (nullable = false)\n |-- aqi_next_1d: double (nullable = true)\n |-- aqi_next_3d: double (nullable = true)\n |-- aqi_next_7d: double (nullable = true)\n |-- target_high_aqi_tomorrow: integer (nullable = false)\n |-- target_severe_aqi_tomorrow: integer (nullable = false)\n |-- feature_timestamp: timestamp (nullable = false)\n |-- feature_version: string (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "print(\"FINAL: Creating Gold layer schema\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Select final feature set\n",
    "gold_final = gold_df.select(\n",
    "    # Identifiers\n",
    "    \"date\", \"city\", \"year\", \"month\", \"day_of_week\", \"quarter\", \"season\",\n",
    "\n",
    "    # Current values\n",
    "    \"aqi\", \"station_count\", \"aqi_category\", \"aqi_risk_level\",\n",
    "    \"prominent_pollutant\", \"is_weekend\",\n",
    "\n",
    "    # Risk flags (from Silver layer - needed for aggregations)\n",
    "    \"is_high_pollution\",\n",
    "    \"is_severe_pollution\",\n",
    "\n",
    "    # Lag features (5)\n",
    "    \"aqi_lag_1\", \"aqi_lag_3\", \"aqi_lag_7\", \"aqi_lag_14\", \"aqi_lag_30\",\n",
    "\n",
    "    # Rolling statistics (7)\n",
    "    \"aqi_rolling_avg_7\", \"aqi_rolling_avg_14\", \"aqi_rolling_avg_30\",\n",
    "    \"aqi_rolling_std_7\", \"aqi_rolling_std_14\",\n",
    "    \"aqi_rolling_max_7\", \"aqi_rolling_min_7\",\n",
    "\n",
    "    # Change features (4)\n",
    "    \"aqi_change_1d\", \"aqi_change_7d\",\n",
    "    \"aqi_pct_change_1d\", \"aqi_pct_change_7d\",\n",
    "\n",
    "    # City baselines (5)\n",
    "    \"city_avg_aqi\", \"city_std_aqi\",\n",
    "    \"aqi_deviation_from_city_avg\", \"aqi_z_score\", \"aqi_percentile_in_city\",\n",
    "\n",
    "    # Cyclical encodings (6)\n",
    "    \"month_sin\", \"month_cos\",\n",
    "    \"day_of_week_sin\", \"day_of_week_cos\",\n",
    "    \"day_of_month_sin\", \"day_of_month_cos\",\n",
    "\n",
    "    # Interaction features (3)\n",
    "    \"is_winter_high_pollution_city\",\n",
    "    \"weekend_pollution_delta\",\n",
    "    \"is_reliable_measurement\",\n",
    "\n",
    "    # Target variables (5)\n",
    "    \"aqi_next_1d\", \"aqi_next_3d\", \"aqi_next_7d\",\n",
    "    \"target_high_aqi_tomorrow\", \"target_severe_aqi_tomorrow\",\n",
    "\n",
    "    # Metadata\n",
    "    current_timestamp().alias(\"feature_timestamp\"),\n",
    "    lit(\"gold_v1\").alias(\"feature_version\")\n",
    ")\n",
    "\n",
    "print(f\"Gold layer records: {gold_final.count():,}\")\n",
    "print(f\"Gold layer features: {len(gold_final.columns)}\")\n",
    "print(\"\\nSchema:\")\n",
    "gold_final.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfe366f7-6d15-410c-a436-083c4fc71048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Gold data:\n+----------+----+-----+---------+------------------+-----------+\n|      date|city|  aqi|aqi_lag_1| aqi_rolling_avg_7|aqi_next_1d|\n+----------+----+-----+---------+------------------+-----------+\n|2015-05-01|Agra|179.0|     NULL|             179.0|      135.0|\n|2015-05-02|Agra|135.0|    179.0|             157.0|       84.0|\n|2015-05-03|Agra| 84.0|    135.0|132.66666666666666|      104.0|\n|2015-05-04|Agra|104.0|     84.0|             125.5|       88.0|\n|2015-05-05|Agra| 88.0|    104.0|             118.0|       91.0|\n|2015-05-06|Agra| 91.0|     88.0|             113.5|       65.0|\n|2015-05-07|Agra| 65.0|     91.0|106.57142857142857|       62.0|\n|2015-05-08|Agra| 62.0|     65.0| 89.85714285714286|      294.0|\n|2015-05-09|Agra|294.0|     62.0|112.57142857142857|       56.0|\n|2015-05-10|Agra| 56.0|    294.0|108.57142857142857|       78.0|\n+----------+----+-----+---------+------------------+-----------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Verify data quality\n",
    "print(\"Sample Gold data:\")\n",
    "gold_final.select(\"date\", \"city\", \"aqi\", \"aqi_lag_1\", \"aqi_rolling_avg_7\", \"aqi_next_1d\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d039e045-c705-40e8-8062-42de5a667e89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Save Gold Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0626e729-460d-485d-bc6f-cfd139e934f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Gold layer to Delta Lake...\n------------------------------------------------------------\nML-ready records (with 30+ days history): 289,034\nGold table created: aqi_india.gold.aqi_ml_features\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving Gold layer to Delta Lake...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Filter to only records with valid lag features (need at least 30 days history)\n",
    "gold_ml_ready = gold_final.filter(col(\"aqi_lag_30\").isNotNull())\n",
    "\n",
    "print(f\"ML-ready records (with 30+ days history): {gold_ml_ready.count():,}\")\n",
    "\n",
    "# Save Gold ML features table\n",
    "gold_ml_ready.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .partitionBy(\"year\") \\\n",
    "    .saveAsTable(T_GOLD)\n",
    "\n",
    "print(\"Gold table created: aqi_india.gold.aqi_ml_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f46adab6-1530-497d-84cc-be252fcb6f48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Gold table...\nGold table optimized!\n"
     ]
    }
   ],
   "source": [
    "# Optimize Gold table\n",
    "print(\"Optimizing Gold table...\")\n",
    "try:\n",
    "    spark.sql(f\"OPTIMIZE {T_GOLD} ZORDER BY (city, date)\")\n",
    "except Exception as e:\n",
    "    print(\"OPTIMIZE skipped:\", e)\n",
    "print(\"Gold table optimized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2b1f60d-598b-4c52-b378-1e432022fdcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Additional Gold Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf349a0f-c2e2-487c-a6d8-e67568db2227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating city summary table...\nCity summary table created: aqi_india.gold.city_summary\n+-----------+-------------+----------+----------+------------------+------------------+-------+-------+------------------+-------------------+---------------------+------------------+\n|       city|total_records|first_date| last_date|           avg_aqi|           std_aqi|min_aqi|max_aqi|      avg_stations|high_pollution_days|severe_pollution_days|high_pollution_pct|\n+-----------+-------------+----------+----------+------------------+------------------+-------+-------+------------------+-------------------+---------------------+------------------+\n| Jharsuguda|            1|2018-02-04|2018-02-04|             282.0|              NULL|  282.0|  282.0|               1.0|                  1|                    0|             100.0|\n|   Byrnihat|          281|2022-12-24|2023-12-31|248.67259786476868| 93.40514437888999|   49.0|  442.0|               1.0|                191|                   11| 67.97153024911033|\n|  Begusarai|          357|2022-04-05|2023-12-22|248.14005602240897| 133.8275449594906|   27.0|  474.0|               1.0|                214|                   59|59.943977591036415|\n|      Angul|           62|2023-10-26|2023-12-31| 238.1290322580645| 80.02038344235322|   59.0|  370.0|               1.0|                 43|                    0| 69.35483870967742|\n|  Ghaziabad|         2418|2017-05-03|2023-12-31| 221.6451612903226|  114.407096272242|   14.0|  500.0|2.8999172870140613|               1273|                  185| 52.64681555004136|\n|      Delhi|         3143|2015-05-01|2023-12-31| 217.1358574610245| 104.0114187729274|   41.0|  497.0| 24.34584791600382|               1648|                  146| 52.43398027362392|\n|      Siwan|          587|2021-11-23|2023-12-31|216.19420783645657|  114.466009532993|   34.0|  488.0|               1.0|                283|                   42| 48.21124361158432|\n|    Bhiwadi|         2063|2017-10-16|2023-12-31| 215.9219583131362| 98.05034543640359|   28.0|  483.0|               1.0|               1122|                   58|54.386815317498794|\n|Barrackpore|           27|2023-12-02|2023-12-31| 215.1851851851852| 66.37251344728887|   32.0|  320.0|               1.0|                 18|                    0| 66.66666666666666|\n|    Chhapra|          674|2021-11-23|2023-12-31| 215.0474777448071|107.43615181704125|   22.0|  452.0|               1.0|                354|                   23| 52.52225519287834|\n+-----------+-------------+----------+----------+------------------+------------------+-------+-------+------------------+-------------------+---------------------+------------------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating city summary table...\")\n",
    "\n",
    "city_summary = gold_final.groupBy(\"city\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_records\"),\n",
    "        min(\"date\").alias(\"first_date\"),\n",
    "        max(\"date\").alias(\"last_date\"),\n",
    "        avg(\"aqi\").alias(\"avg_aqi\"),\n",
    "        stddev(\"aqi\").alias(\"std_aqi\"),\n",
    "        min(\"aqi\").alias(\"min_aqi\"),\n",
    "        max(\"aqi\").alias(\"max_aqi\"),\n",
    "        avg(\"station_count\").alias(\"avg_stations\"),\n",
    "        sum(when(col(\"is_high_pollution\") == True, 1).otherwise(0)).alias(\"high_pollution_days\"),\n",
    "        sum(when(col(\"is_severe_pollution\") == True, 1).otherwise(0)).alias(\"severe_pollution_days\")\n",
    "    ) \\\n",
    "    .withColumn(\"high_pollution_pct\", col(\"high_pollution_days\") / col(\"total_records\") * 100) \\\n",
    "    .orderBy(\"avg_aqi\", ascending=False)\n",
    "\n",
    "city_summary.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(f\"{CATALOG}.gold.city_summary\")\n",
    "\n",
    "print(\"City summary table created: aqi_india.gold.city_summary\")\n",
    "city_summary.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acef3b37-ffc7-42cf-8ed4-33c20a868e72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating monthly trends table...\nMonthly trends table created: aqi_india.gold.monthly_trends\n+----+-----+-------------+----------------+------------------+------------------+-------+-------+--------------------+----------------------+\n|year|month|total_records|cities_reporting|           avg_aqi|           std_aqi|min_aqi|max_aqi|high_pollution_count|severe_pollution_count|\n+----+-----+-------------+----------------+------------------+------------------+-------+-------+--------------------+----------------------+\n|2015|    5|          316|              11|146.80379746835442| 80.65131367951713|   42.0|  482.0|                  78|                     3|\n|2015|    6|          286|              11|113.73776223776224|  67.0569627497433|   28.0|  356.0|                  32|                     0|\n|2015|    7|          332|              11| 86.96385542168674| 50.50564762369056|   15.0|  351.0|                  11|                     0|\n|2015|    8|          331|              13| 86.10574018126889| 48.16226673078668|   27.0|  351.0|                  12|                     0|\n|2015|    9|          351|              15| 112.6068376068376|58.064096198935765|   26.0|  420.0|                  29|                     2|\n|2015|   10|          377|              15|181.77453580901857| 80.89525397579199|   39.0|  500.0|                 143|                     1|\n|2015|   11|          371|              15| 246.8490566037736|122.34489957415592|   31.0|  450.0|                 229|                    32|\n|2015|   12|          431|              20|249.41299303944317| 123.0428218826065|   41.0|  489.0|                 265|                    48|\n|2016|    1|          506|              22|257.62450592885375|125.99197409709923|   27.0|  488.0|                 298|                    86|\n|2016|    2|          486|              22| 193.9156378600823| 90.95989306670108|   31.0|  457.0|                 209|                     4|\n|2016|    3|          457|              22|151.05908096280086| 73.00206384991112|   31.0|  383.0|                 101|                     0|\n|2016|    4|          442|              23| 165.1131221719457| 87.30770699333489|   34.0|  500.0|                 142|                     4|\n+----+-----+-------------+----------------+------------------+------------------+-------+-------+--------------------+----------------------+\nonly showing top 12 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating monthly trends table...\")\n",
    "\n",
    "monthly_trends = gold_final.groupBy(\"year\", \"month\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_records\"),\n",
    "        countDistinct(\"city\").alias(\"cities_reporting\"),\n",
    "        avg(\"aqi\").alias(\"avg_aqi\"),\n",
    "        stddev(\"aqi\").alias(\"std_aqi\"),\n",
    "        min(\"aqi\").alias(\"min_aqi\"),\n",
    "        max(\"aqi\").alias(\"max_aqi\"),\n",
    "        sum(when(col(\"is_high_pollution\") == True, 1).otherwise(0)).alias(\"high_pollution_count\"),\n",
    "        sum(when(col(\"is_severe_pollution\") == True, 1).otherwise(0)).alias(\"severe_pollution_count\")\n",
    "    ) \\\n",
    "    .orderBy(\"year\", \"month\")\n",
    "\n",
    "monthly_trends.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(f\"{CATALOG}.gold.monthly_trends\")\n",
    "\n",
    "print(\"Monthly trends table created: aqi_india.gold.monthly_trends\")\n",
    "monthly_trends.show(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91e00a08-e9af-46f9-8d15-1809d7ed7233",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# 4. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e73ceae-51a3-4b5d-bd66-a2f40a3186dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\nDATA PIPELINE SUMMARY\n================================================================================\n\nLAYER SUMMARY:\n  Bronze (Raw):      299,976 records\n  Silver (Cleaned):  297,209 records\n  Gold (ML-Ready):   289,034 records\n\nTABLES CREATED:\n  1. aqi_india.bronze.aqi_bulletins\n  2. aqi_india.silver.aqi_cleaned\n  3. aqi_india.gold.aqi_ml_features\n  4. aqi_india.gold.city_summary\n  5. aqi_india.gold.monthly_trends\n\nFEATURE GROUPS IN GOLD LAYER:\n  - Lag features: 5 (1d, 3d, 7d, 14d, 30d)\n  - Rolling stats: 7 (avg, std, min, max)\n  - Change features: 4 (absolute & percentage)\n  - City baselines: 5 (deviation, z-score, percentile)\n  - Cyclical encoding: 6 (sin/cos for time)\n  - Interaction features: 3\n  - Target variables: 5 (1d, 3d, 7d + binary)\n\nREADY FOR ML MODELING!\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATA PIPELINE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "bronze_count = spark.table(T_BRONZE).count()\n",
    "silver_count = spark.table(T_SILVER).count()\n",
    "gold_count = spark.table(T_GOLD).count()\n",
    "\n",
    "print(f\"\\nLAYER SUMMARY:\")\n",
    "print(f\"  Bronze (Raw):      {bronze_count:,} records\")\n",
    "print(f\"  Silver (Cleaned):  {silver_count:,} records\")\n",
    "print(f\"  Gold (ML-Ready):   {gold_count:,} records\")\n",
    "\n",
    "print(f\"\\nTABLES CREATED:\")\n",
    "print(f\"  1. aqi_india.bronze.aqi_bulletins\")\n",
    "print(f\"  2. aqi_india.silver.aqi_cleaned\")\n",
    "print(f\"  3. aqi_india.gold.aqi_ml_features\")\n",
    "print(f\"  4. aqi_india.gold.city_summary\")\n",
    "print(f\"  5. aqi_india.gold.monthly_trends\")\n",
    "\n",
    "print(f\"\\nFEATURE GROUPS IN GOLD LAYER:\")\n",
    "print(f\"  - Lag features: 5 (1d, 3d, 7d, 14d, 30d)\")\n",
    "print(f\"  - Rolling stats: 7 (avg, std, min, max)\")\n",
    "print(f\"  - Change features: 4 (absolute & percentage)\")\n",
    "print(f\"  - City baselines: 5 (deviation, z-score, percentile)\")\n",
    "print(f\"  - Cyclical encoding: 6 (sin/cos for time)\")\n",
    "print(f\"  - Interaction features: 3\")\n",
    "print(f\"  - Target variables: 5 (1d, 3d, 7d + binary)\")\n",
    "\n",
    "print(f\"\\nREADY FOR ML MODELING!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe4d3b35-0938-4c0b-82f8-623216a0ccac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Gold table schema:\nroot\n |-- date: date (nullable = true)\n |-- city: string (nullable = true)\n |-- year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day_of_week: integer (nullable = true)\n |-- quarter: integer (nullable = true)\n |-- season: string (nullable = true)\n |-- aqi: double (nullable = true)\n |-- station_count: integer (nullable = true)\n |-- aqi_category: integer (nullable = true)\n |-- aqi_risk_level: string (nullable = true)\n |-- prominent_pollutant: string (nullable = true)\n |-- is_weekend: boolean (nullable = true)\n |-- is_high_pollution: boolean (nullable = true)\n |-- is_severe_pollution: boolean (nullable = true)\n |-- aqi_lag_1: double (nullable = true)\n |-- aqi_lag_3: double (nullable = true)\n |-- aqi_lag_7: double (nullable = true)\n |-- aqi_lag_14: double (nullable = true)\n |-- aqi_lag_30: double (nullable = true)\n |-- aqi_rolling_avg_7: double (nullable = true)\n |-- aqi_rolling_avg_14: double (nullable = true)\n |-- aqi_rolling_avg_30: double (nullable = true)\n |-- aqi_rolling_std_7: double (nullable = true)\n |-- aqi_rolling_std_14: double (nullable = true)\n |-- aqi_rolling_max_7: double (nullable = true)\n |-- aqi_rolling_min_7: double (nullable = true)\n |-- aqi_change_1d: double (nullable = true)\n |-- aqi_change_7d: double (nullable = true)\n |-- aqi_pct_change_1d: double (nullable = true)\n |-- aqi_pct_change_7d: double (nullable = true)\n |-- city_avg_aqi: double (nullable = true)\n |-- city_std_aqi: double (nullable = true)\n |-- aqi_deviation_from_city_avg: double (nullable = true)\n |-- aqi_z_score: double (nullable = true)\n |-- aqi_percentile_in_city: double (nullable = true)\n |-- month_sin: double (nullable = true)\n |-- month_cos: double (nullable = true)\n |-- day_of_week_sin: double (nullable = true)\n |-- day_of_week_cos: double (nullable = true)\n |-- day_of_month_sin: double (nullable = true)\n |-- day_of_month_cos: double (nullable = true)\n |-- is_winter_high_pollution_city: integer (nullable = true)\n |-- weekend_pollution_delta: double (nullable = true)\n |-- is_reliable_measurement: boolean (nullable = true)\n |-- aqi_next_1d: double (nullable = true)\n |-- aqi_next_3d: double (nullable = true)\n |-- aqi_next_7d: double (nullable = true)\n |-- target_high_aqi_tomorrow: integer (nullable = true)\n |-- target_severe_aqi_tomorrow: integer (nullable = true)\n |-- feature_timestamp: timestamp (nullable = true)\n |-- feature_version: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Final verification\n",
    "print(\"Final Gold table schema:\")\n",
    "spark.table(T_GOLD).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1daad907-5cf8-4010-a196-8ba3fd96b6b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ML-ready data:\n+----------+-----+-----+---------+------------------+------------------+-----------+------------------------+\n|      date| city|  aqi|aqi_lag_1| aqi_rolling_avg_7|       aqi_z_score|aqi_next_1d|target_high_aqi_tomorrow|\n+----------+-----+-----+---------+------------------+------------------+-----------+------------------------+\n|2023-12-31|Delhi|382.0|    400.0| 380.2857142857143|  1.58505810692669|       NULL|                       0|\n|2023-12-30|Delhi|400.0|    382.0|384.42857142857144|1.7581160289544313|      382.0|                       1|\n|2023-12-29|Delhi|382.0|    358.0|391.57142857142856|  1.58505810692669|      400.0|                       1|\n|2023-12-28|Delhi|358.0|    380.0|395.42857142857144| 1.354314210889702|      382.0|                       1|\n|2023-12-27|Delhi|380.0|    377.0|395.85714285714283|1.5658294489236078|      358.0|                       1|\n|2023-12-26|Delhi|377.0|    383.0| 382.2857142857143|1.5369864619189841|      380.0|                       1|\n|2023-12-25|Delhi|383.0|    411.0| 369.2857142857143|1.5946724359282314|      377.0|                       1|\n|2023-12-24|Delhi|411.0|    450.0| 361.7142857142857|1.8638736479713842|      383.0|                       1|\n|2023-12-23|Delhi|450.0|    409.0| 350.2857142857143|  2.23883247903149|      411.0|                       1|\n|2023-12-22|Delhi|409.0|    361.0|336.57142857142856|1.8446449899683017|      450.0|                       1|\n+----------+-----+-----+---------+------------------+------------------+-----------+------------------------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Sample ML-ready data\n",
    "print(\"Sample ML-ready data:\")\n",
    "spark.table(T_GOLD) \\\n",
    "    .select(\"date\", \"city\", \"aqi\", \"aqi_lag_1\", \"aqi_rolling_avg_7\", \"aqi_z_score\", \"aqi_next_1d\", \"target_high_aqi_tomorrow\") \\\n",
    "    .filter(col(\"city\") == \"Delhi\") \\\n",
    "    .orderBy(\"date\", ascending=False) \\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "284a99d6-85a0-4616-9b9b-e3892d7db24d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "AQI Data_cleaning.ipynb",
   "widgets": {
    "raw_dir": {
     "currentValue": "/Volumes/aqi_india/bronze/raw_data/",
     "nuid": "8271deb4-241a-4328-9118-84620692378b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/Volumes/aqi_india/bronze/raw_data/",
      "label": null,
      "name": "raw_dir",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/Volumes/aqi_india/bronze/raw_data/",
      "label": null,
      "name": "raw_dir",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "raw_file_hint": {
     "currentValue": "AllIndiaBulletins",
     "nuid": "5fe336aa-0162-4014-b1b5-202fbb57f0cb",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "AllIndiaBulletins",
      "label": null,
      "name": "raw_file_hint",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "AllIndiaBulletins",
      "label": null,
      "name": "raw_file_hint",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}